Web Data Connector
Ajay Bidyarthy
"March 13, 2025"
Client Background
Client: A Leading Marketing Tech Firm in Australia
Industry Type: Marketing
Services: Marketing Solutions
Organization Size: 50+
Project Objective
To make a software code that takes data from a source and ingests it into a database present on a server. The scripts should automatically execute after regular intervals of time.
Project Description
"The client had several data sources that were updated with new data regularly. The client wanted software that triggers itself automatically and takes data from those data sources and ingests it into a database that is hosted on a Linode server. Also, the date parameters in the query should be changed dynamically using the current date. Further, we had to assist in setting up the Tableau BI tool on the client’s PC and connect the Postgres database to the tableau."
Our Solution
We setup a linux server on linode.
Install Postgres on this linux server.
Create a database and create a new user. Grant this new user all privileges on the database.
Create a table within the database. This table has columns with datatypes as specified by the client.
Write a python script that makes GET request to the client specified data source and store the response in json format.
"Inside the python script itself, establish  a connection to our postgres database using the pscopg2 module and user credentials."
Ingest the data into postgres using INSERT query in python script.
"Write code to get the today’s date using the datetime module. Using this, calculate yesterday’s date. Now we can use these as parameters inside our query to the data source."
Move these python files to our server.
Install and setup Cron on our server.
Add the task to run specified python files at regular intervals to Cron.
Repeat steps 4 to 11 for every new data source.
Project Deliverables
Python Script
Working linode server with cron installed
Tableau installation and connection to postgres
Project Documentation
Tools used
Linode server
VS Code
Language/techniques used
Python
Bash
PSQL.
Skills used
Python programming
Postgres SQL
Linux scripting
Databases used
Postgres
Web Cloud Servers used
Linode
What are the technical Challenges Faced during Project Execution
Avoiding duplicates was a challenge.
Since Client was living in Australia all the timezone (on server and in code) were changed to AEDT.
How the Technical Challenges were Solved
Used uniqueid Column to check for duplicates.
Used pytz module to change timezones.
Business Impact
"This solution helps in maintaining a copy of all data sources inside our Postgres database. Also, the data is 24/7 available. Since data inside the Postgres is updated regularly, graphs in the tableau are also up to date."
Project Snapshots
https://lh4.googleusercontent.com/n-2IW5hH-Bbb9jPbmrlgF59DcgYTNACQ1UqOp3Mjre83UnR42WzSmC0qL_q3VaMDLbDTtJbHaGwq9S9RP8yueS9ruR8rtIDONTk0DI_YJpipw3WYoZcuXl7ZgJC9srFTEWD1oGELEYdNjNC_hg
https://lh4.googleusercontent.com/YuorDUsAJNu1QY0j2eBTjOcTAtpxHXvjo1VzU43UDYKkeBT3lHTsObXih5oVKcJ1FG85HKWeNXL8Dc7DuitAMNY3MEMiSAH7PlucblATwx4X8O-LPTqp8Bedm9gcLNgzThQGg8MhYKrAVn1gkg
https://lh3.googleusercontent.com/z96cnmp3DRRTbf7o1NiY0mjNd9qtQFCzi55AjegrbybfYH0BKv5Wk65CmhLC2wtUUTrwDpfcn4Y9ge0eQ5xIjU80uunUxum-ycGwcuARqkEr1Vw8MP7RUgl793jvU9a_bW_wzTeu9lRoxVTUxA
https://lh3.googleusercontent.com/of1lj-3dJtvI929sAkwKOGv_g0EiZM2wNXjk-PUUwaOo2jb9mHP7lStWWqVLJGNK9jMZT9o9DQX7UHfQ1VHX8m4mX4Ray2auWWmxAEQakH0DD7vFxGz30dUcGffuYZOs8lzwKKlGdEclmm3xGQ
https://lh6.googleusercontent.com/0gNT0pS9WtE6nXZEakAMo-Wu2pRi00ghiHJILRZigUKyKeJIxm2bBPEZHLjwldmKsoNDExct5HUAE-ZIfjU4UpdltBYmWP4h3lGwh8USkEyGr5AAEQ046WjUEN8BweboPmlDQjidXYoWLpcGrA
https://lh6.googleusercontent.com/VZ91OfgYHGS0AwbK4_bjy6HNt2mj5JS5ohYJARloXNQTWFyVLuyYkWxCwtrOTPVB8xqs5iPcNgctNxtnGLBVH3N8zrTnVAgQUijtzVTHdgyoQ_xLTxGskNwY-eSVTQejyLNWvfKoPDrtoj4fAA
https://lh5.googleusercontent.com/QErIn2PHDzX3AH19oO9Y6cLhPWPFoLKoohHOCqbR9ufSYW6L_9sikRXAAHfYM2tBL5D4QaznelvqxY0hgC8kSR49ZRV0IjZextWzAinYigYpWCCLX_ttw5r_FrMx_kPn4ebTXuGPnpq0V2xS3w
https://lh5.googleusercontent.com/gJSmDiVOSoR_DIC8DcM-psJMvdbE8BLDcAGjZrANGKcHJyfQ-EjMqROPkmqcnVYt37mvR1J_JvAYILJQrQRFA8m59oGXBgDCSvLYw0kk1aKne4xlUS0SHBSgt8y-4BLCYrlcKI2DvNBcofXGdg
https://lh3.googleusercontent.com/tTpFpf9b9-IApyoVXX9bbiBf-yPPF0OBOLBB2Fm8rie1o04YNlFtHJIO1yVsM5u8ZFaFgZvfHYNCrYdcbjUcj4hY4n7-QS83xR_JIPCe82oXGSOLBFD8yJzVy-VIntv4upo5l2X02m998cR1bw
https://lh5.googleusercontent.com/Gtp93KFyCNX7FT3-K65L5h99Hq83bg9N80p9I4O5e-o10zP4PCBpDms9ANpX9sEESQ2qX6m-bUjoC7nTxCiEVi7e-A9EP_xprMyCJvSAkKDG3sZSY7Fmn_E6zb2Fe6Nb3VCuw4CTw76Bxc0cCQ
Project website url
https://github.com/X360pro/Web-connector-for-tableu
https://www.youtube.com/embed/f-2GdBjHLFA?feature=oembed&enablejsapi=1
We setup a linux server on linode.
Install Postgres on this linux server.
Create a database and create a new user. Grant this new user all privileges on the database.
Create a table within the database. This table has columns with datatypes as specified by the client.
Write a python script that makes GET request to the client specified data source and store the response in json format.
"Inside the python script itself, establish  a connection to our postgres database using the pscopg2 module and user credentials."
Ingest the data into postgres using INSERT query in python script.
"Write code to get the today’s date using the datetime module. Using this, calculate yesterday’s date. Now we can use these as parameters inside our query to the data source."
Move these python files to our server.
Install and setup Cron on our server.
Add the task to run specified python files at regular intervals to Cron.
Repeat steps 4 to 11 for every new data source.
Python Script
Working linode server with cron installed
Tableau installation and connection to postgres
Project Documentation
Avoiding duplicates was a challenge.
Since Client was living in Australia all the timezone (on server and in code) were changed to AEDT.
Used uniqueid Column to check for duplicates.
Used pytz module to change timezones.
