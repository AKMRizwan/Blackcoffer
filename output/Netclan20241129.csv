Big Data solution to an online multivendor marketplace eCommerce business
Ajay Bidyarthy
"October 24, 2024"
Client Background
"Client: A leading eCommerce firm in the USA, Columbia, India, and Latin America"
Gangala promotes local shops selling a wide variety of products at great prices. Easily find the best offers using our price comparison tool. It’s a WIN WIN for …
Industry Type:  eCommerce
"Services: e-commerce, retail business"
Organization Size: 100+
Project Objective
"To give User experience of easy and convenient Shopping by searching all the products like any medicines , Clothes , Gadgets etc in a single Website without going through all the E-Commerce Sites and make shopping easy and get the most affordable and best product."
Project Description
"It’s an E-Commerce Sites that’s helps customer to compare different  products that were available on different E-Commerce Sites like Flipkart , Amazon , Netmeds etc.It’s helps the user to visit only one sites to get what they need and find the perfect product without visiting all the sites.The gives the user a great and friendly Experience in Buying any Products.It’s Also have some Unique Similar Products Recommendation Based on user search and also have a ChatBot That’s solves User Query .It’s uses Big data and Rest API that’s help the projects for regular updates and regular fetching of the new products."
Our Solution
"In BlackCoffer We create the flow of the Big Data and all Backend Solution That is requires for this futuristic E-Commerce Sites.We Create Pipelines for the data of all the products and their price and url fetch from different E-Commerce Sites using Custom made APIs And perform many data cleaning, data transformation and data validation techniques to make sure the standard of data to be used by Our Sites .We also get Additional Feature from the scraped data By using Different APIs . We also create automation and custom python scripts that helps us to achieve some outstanding data related tasks."
Project Deliverables
Python script for performing ETL and Cypher Query for big data Handling.
Tools used
Jupyter Notebook
DSS
VS Code
Language/techniques used
Python
No SQl
Cypher
ETL
Models used
Similar Price API
Whatsapp Chat API
Similarity Server to get similar products
Skills used
Data Engineering
Data Analysis
Python Programming
Rest APIs
Databases used
DSS
NEO4J
MongoDB
Web Cloud Servers used
Linode
AWS
What are the technical Challenges Faced during Project Execution
Data Cleaning : -The Scraped that will be used by our sites is coming from different sources and also it’s not’s that clean to be used by sites .This is the very first problem every data scientist faced during the whole process.
Data Merging :-  The data is scraped from around 140 sources that’s why it’s very difficult to maintain the attributes that should be used by all the sources and we can get a clean and sufficient amount of data to process.
Data Validation :-  There are many records that have null values and missing values that disturb the users experience a lot .That should be handle with very care.
How the Technical Challenges were Solved
Data Cleaning : – For Data cleaning we used Python Data Frame and Pandas and data structure and handles the data cleaning and optimize our data for get correct data format and useful data.
Data Merging : –  For data Merging and data transformation we used pandas that help to get the appropriate data that can used further And also make Python pipelines for future updation.
Data Validation :- For that data validation we use some fundamental property and feature selection that’s help us to make the appropriate data format and records to be used In our sites.
Project Snapshots
https://lh5.googleusercontent.com/_HhLfZOFOISXXs7Mpx4jpDVWQHW2bNLjAE--VW7KerxdqrgvYL0ePXlicgfY9cmegOXr2FjJKIN-pbWlfRSGkkpaVdayhQUGWPy5pjQfWHf_SmTEOJzs0uSGrya3Kw3twHeluvH7
https://lh4.googleusercontent.com/o_JuYRoc80XDwMnnUQJF_4vXj6O7NGwPrKKg73I9DBowoWqAp5cOmm3g-PO3hBGU8zQbYdfGCjQyKXDdfH9e6SgMi0sO8ztqjOWX1l_XdWxcMu4oLzsWcJ6RVxNUtlUy0omcYOHk
https://lh6.googleusercontent.com/GZqTIL_djYY8c5dWBirAZswI0IWLer243QkH_B5y4jkogrBP0nPZycSFy8tUDiDxyECb_QQuHMibcq8Zp6wTRT9V_7VKsIFTgSFBucpFrfrzkxGAXXXx7p_OK8VvdGEv65J0lxnn
https://lh3.googleusercontent.com/k2jz-V1ZQIY2CDyYACxmBO8Z62dEOLo-Hh5_hY-WblAIkBAKmSTCH0zj1C3raBnol4AFmpJb7Kz1E5AfLre_k8bJfmwqRarJ25H5xaWJ96lKwKRFcm0kbVR7xseWTAE21PN_KoU0
https://lh3.googleusercontent.com/k2jz-V1ZQIY2CDyYACxmBO8Z62dEOLo-Hh5_hY-WblAIkBAKmSTCH0zj1C3raBnol4AFmpJb7Kz1E5AfLre_k8bJfmwqRarJ25H5xaWJ96lKwKRFcm0kbVR7xseWTAE21PN_KoU0
https://lh5.googleusercontent.com/UACe4zNot3xXlqwO8cvlBQeiWbNPkZUnt7oJRyKASld7wskT5nZQl6b4gzyYOp4UnUsJXp8scwnX7Z7-uhLBz_1SyqPAMHJaK3iNGjtV45zcsfQjG_KcXf9qy-bRZH3oV8esAgjH
https://lh3.googleusercontent.com/1-UuIS7kITvwZkL5ISkMnbh0Jtjhy0GRyEGPlRV8-YZiwDc-dOGb0e5RGtIAzWaF-78c-S3-T-tzR6x189N6dlTceJHv6OWkYlJZJZi9_UJK6Mewp86DVowVYb0w0bRFlxfnalLn
https://lh3.googleusercontent.com/iETtKWy4zUIL2LDREDIFAesdEZ8fGtjW6qkKdZiMt0ozQauTayDYr-zIdVZDvj_D6_yZz8EgZn_uDI0Cyzs6GCLNlGq3XNh1S2ncnOlWc5VHG2hiOiYyclelFpJMAi2m8bvf1aFr
https://lh3.googleusercontent.com/ys1Q7gvyg6zISpto2NVLLa0ulq3kx8a8fXEBMzzH0sSocJpdYml4lruI9uTaWU2Wc4HNVGBzECIgC7A-c0AsPQ0EGRDbrr9mTfuwEnSkmSRdjf6XW_wgE2h614R2ign8fUQXFDqf
https://lh4.googleusercontent.com/4AnR6AJ-fqV2RuTTDVHAD_Y8619ghuc-D440YkHlvUO_Vv4c0LD6U_izZyyCBzcHd5xClIw53C1mW_ENWz1Hj4yJpC3AncF8w6UT_4lABEQhrsDEVqW5gxArKvDkFs2zIjzmjweM
Project website url
https://gangala.in/
Jupyter Notebook
DSS
VS Code
Python
No SQl
Cypher
ETL
Similar Price API
Whatsapp Chat API
Similarity Server to get similar products
Data Engineering
Data Analysis
Python Programming
Rest APIs
DSS
NEO4J
MongoDB
Linode
AWS
Data Cleaning : -The Scraped that will be used by our sites is coming from different sources and also it’s not’s that clean to be used by sites .This is the very first problem every data scientist faced during the whole process.
Data Merging :-  The data is scraped from around 140 sources that’s why it’s very difficult to maintain the attributes that should be used by all the sources and we can get a clean and sufficient amount of data to process.
Data Validation :-  There are many records that have null values and missing values that disturb the users experience a lot .That should be handle with very care.
Data Cleaning : – For Data cleaning we used Python Data Frame and Pandas and data structure and handles the data cleaning and optimize our data for get correct data format and useful data.
Data Merging : –  For data Merging and data transformation we used pandas that help to get the appropriate data that can used further And also make Python pipelines for future updation.
Data Validation :- For that data validation we use some fundamental property and feature selection that’s help us to make the appropriate data format and records to be used In our sites.
